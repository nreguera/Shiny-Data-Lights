
```{r SET, eval=TRUE, include=FALSE}
# General setup parameters

# SET: Settings
# LDA: Load Data
# CLN: Clean Data
# PRP: Process Data
# EDA: Explore Data
# MOD: Model Data

myPaths <- .libPaths() # get the current library paths
myPaths <- c("E:/R/Libraries/4.0.2", myPaths[1])  # add the new path
.libPaths(myPaths)  # reassign them
.libPaths() # check the libraries paths

# General chunk parameters
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE, 
                      eval = TRUE, 
                      include = FALSE, 
                      echo = FALSE,
                      cache = FALSE)


```


```{r SET}
# Load libraries

# Load data
library(readxl)
library(Rnightlights)

# Process data
library(sp)
library(tidyverse)
library(factoextra)
library(lubridate)
library(reshape)
library(rgdal)
require(rgeos)
library(data.table)
library(sf)

# Explore data
library(ggplot2)
library(tmap)
library(highcharter)
library(leaflet)
library(hrbrthemes)
library(plotly)
library(viridis)
library(ggExtra)
library(tidyr) 

# Model data

# Clear console
cat("\014")

```


```{r SET}

# Directories
dir_cache = "Cache/"
dir_outputs = "Outputs/"
dir_data = "Data/"

```


```{r SET, eval=FALSE}
# Setup specific libraries parameters

# Regional setup
Sys.setlocale("LC_TIME", "English")
Sys.setlocale(locale="UTF-8")

# Setup to improve performance downloading data for Rnightlights
pkgOptions(downloadMethod="aria", extractMethod="rast", numCores=4, deleteTiles=TRUE)

# to know which admLevel select in the getCtryNlData function AND create the CSV structure
searchAdmLevel(ctryCode = "MMR", 
               custPolyPath = paste0(dir_data,
                                     "/geo/MIMU/mmr_polbnda_250k_adm3_mimu.zip",
                                     sep="",
                                     collapse=NULL))

```


```{r PRP3}
# Define a function to extract the month

expand_dates <- function(start, end) {

    # the number of entries we want to add
  to_add <- month(end) - month(start) 

  # Take the start date, roll it forwards until the month is equal to the end month
  start_dates <- start + months(0:to_add)

  # everything but the first start_date is rolled back to first of month
  start_dates <- c(start_dates[1],
                   rollback(start_dates[-1], roll_to_first = T))

  # end dates are just the start_dates rolled forwards to the end of the month
  # apply to all but last, thats the end date
  end_dates <- c(rollback(ceiling_date(start_dates[-length(start_dates)], unit = "months")), end)

  data.frame(start_dates = start_dates,
             end_dates = end_dates)
}

```


```{r LDA, eval=FALSE}
# Download Nightlights data by country

# (ISO3) country code
ctry <- "MMR"

# Download rasters (tiff) and radiance readings (csv)
nl_source <- getCtryNlData(
  ctryCode = ctry, # country
  custPolyPath = "mmr_polbnda_250k_adm3_mimu.zip",
  admLevel = "0_mmr_polbnda_250k_adm3_mimu", # admin level
  nlType = "VIIRS.M", # monthly values
  nlPeriods = nlRange("201204", "201212"),
  ignoreMissing = FALSE, # not ignoring missing values
  nlStats = list("mean", na.rm=FALSE) # aggregation: average 
)

``` 


```{r LDA}
# Load nightlights data

nl_file <- paste(dir_data, "nl/NL_DATA_MMR_ADM3_GADM-3.6-SHPZIP.csv", sep="", collapse=NULL)

nl <- read.csv(file=nl_file,
               header=TRUE, 
               sep=",",
               stringsAsFactors = FALSE)

```


```{r CLN}
# Clean Nightlights dataset

nl_data <- as.data.frame(nl)

# Change the names of the nightlights dataset columns
names(nl_data) [names(nl_data) == "country"] <- "country"
names(nl_data) [names(nl_data) == "division_.yin."] <- "region"
names(nl_data) [names(nl_data) == "district_.kayaing."] <- "district"
names(nl_data) [names(nl_data) == "village.township"] <- "township"
names(nl_data) [names(nl_data) == "area_sq_km"] <- "area"

# No NAs

# There are 2 townships with the same name in the same region, so we will use for the Maubin region
# township the name that appears in the VARNAME_3 column: "Danuphyu"
nl_data[14, 4] <- "Danuphyu"

```


```{r PRP}
# Melt Nightlights data by region, district and township

# Drop country and area
nl_data <- nl_data[,-c(1,5)]

# Convert in a dataframe
nl_data <- as.data.frame(nl_data, stringsAsFactors = FALSE)

# Melt the dataset in a more appropriate format for analysis (short)
# It can be that the same township has the same name for different districts, so we need 
# to include that division when melting
nl_data <- reshape2::melt(nl_data, id=c("region", "district", "township"))

# Convert period (in the column named "variable") in date format
nl_data$variable = gsub("[^[:digit:]]", "", nl_data$variable)
nl_data$variable = sub("(.{4})(.*)", "\\1/\\2", nl_data$variable)
nl_data$variable = paste(nl_data$variable, "/01", sep = "")
nl_data$variable = as.Date(nl_data$variable)

# Assign more identificable names to the columns
colnames(nl_data) <- c("region", "district", "township", "date", "radiance")

```


```{r LDA}
# Load conflict data

# Each row in the dataset represents an event linked to a conflict
# Each conflict can have several events
# Each event can last several months
# Deaths are set by event

cn_file <- paste(dir_data, 
                 "conflicts/ged201.xlsx", 
                 sep="", 
                 collapse=NULL)

# Select columns
cn_colTypes <- c("text", # id
                  "skip", # relid
                  "numeric", # year
                  "numeric", # active_year
                  "skip", # code_status
                  "numeric", # type_of_violence
                  "skip", # conflict_dset_id
                  "numeric", # conflict_new_id
                  "text", # conflict_name
                  "skip", # dyad_dset_id
                  "numeric", # dyad_new_id
                  "text", # dyad_name
                  "skip", # side_a_dset_id
                  "numeric", # side_a_new_id
                  "text", # side_a
                  "skip", # side_b_dset_id
                  "numeric", # side_b_new_id
                  "text", # side_b
                  "numeric", # number_of_sources
                  "skip", # source_article
                  "skip", # source_office
                  "skip", # source_date
                  "skip", # source_headline
                  "skip", # source_original
                  "numeric", # where_prec
                  "text", # where_coordinates
                  "skip", # where_description
                  "skip", # adm_1
                  "skip", # adm_2
                  "numeric", # latitude
                  "numeric", # longitude
                  "skip", # geom_wkt
                  "skip", # priogrid_gid
                  "text", # country
                  "numeric", # country_id
                  "skip", # region
                  "numeric", # event_clarity
                  "numeric", # date_prec
                  "date", # date_start
                  "date", # date_end
                  "numeric", # deaths_a
                  "numeric", # deaths_b
                  "numeric", # deaths_civilians
                  "numeric", # deaths_unknown
                  "numeric", # best
                  "numeric", # high
                  "numeric", # low
                  "skip", # gwnoa
                  "skip") # gwnob

cn <- read_xlsx(path=cn_file,
               col_names=TRUE,
               col_types=cn_colTypes,
               skip=0)

# from the cn data we will create three main dataframes: conflicts, events, and locations

```


```{r CLN}
# Create a dataframe of events from Myanmar

# Select events by country
cn_events = as.data.frame(cn[which(cn$country_id==775), ])
cn_events = select(cn_events, -country, -country_id)

# convert to date
cn_events$date_start = as.Date(cn_events$date_start)
cn_events$date_end = as.Date(cn_events$date_end)

# convert to boolean
cn_events$active_year = as.logical(cn_events$active_year)

# convert to factor
cn_events$date_prec = as.factor(cn_events$date_prec)
cn_events$where_prec = as.factor(cn_events$where_prec)
cn_events$event_clarity = as.factor(as.numeric(cn_events$event_clarity))

# Rename event_clarity to a more meaningful ones
#cn_events$event_clarity[cn_events$event_clarity == 1] <- "High"
#cn_events$event_clarity[cn_events$event_clarity == 2] <- "Low"

# change names
names(cn_events) <- c("id","year","active_year",
                    "type_of_violence","conflict_id","conflict_name","dyad_id","dyad_name",
                    "side_a_id","side_a_name","side_b_id","side_b_name",
                    "sources_number",
                    "location_prec","location_name","latitude","longitude",
                    "event_prec","date_prec","date_start","date_end",
                    "deaths_side_a","deaths_side_b","deaths_civilians",
                    "deaths_unknown","deaths_total","deaths_high","deaths_low")


```


```{r EDA}
# Exploring conflicts dataset

# Explore deaths
cn_explore = cn_events[c("date_start", "deaths_side_a", "deaths_side_b", "deaths_civilians", "deaths_unknown", "deaths_total","deaths_high", "deaths_low")]
cn_explore = melt(cn_explore, "date_start")

# boxplot
plot1 <-ggplot(cn_explore, aes(x=variable, y=value)) +
  geom_boxplot(outlier.colour="black", outlier.shape=16,
             outlier.size=2, notch=FALSE)

# scatterplot
plot1 <- ggplot(cn_explore) +
  geom_point(aes(x=date_start, y=value, color=variable), alpha = 0.4) + 
  facet_wrap( ~ variable, ncol=3)

# events by year
cn_explore = cn_events[c("year", "event_prec")]

ggplot(cn_explore, aes(x=year, fill=event_prec)) +
  geom_histogram(colour='white', size=1)

```


```{r PRP}
# Create a dataframe with locations of conflicts

# A location can have more than one event

cn_locations = cn_events %>%
  group_by(c("longitude","latitude")) %>%
  mutate(n_events=count())




```


```{r LDA}
# Load geographical data

# Country level
geo_file <- paste(dir_data, "geo/gadm36_MMR_0_sp.rds", sep="")
co_geo <- readRDS(geo_file)

# Region/State level
geo_file <- paste(dir_data, "geo/gadm36_MMR_1_sp.rds", sep="")
rg_geo <- readRDS(geo_file)

# District level
geo_file <- paste(dir_data, "geo/gadm36_MMR_2_sp.rds", sep="")
ds_geo <- readRDS(geo_file)

# Township level
geo_file <- paste(dir_data, "geo/gadm36_MMR_3_sp.rds", sep="")
tw_geo <- readRDS(geo_file)

# MIMU Township level
#geo_file <- "E:/Data Lights/Data/geo/mmr_polbnda_250k_adm3_mimu/mmr_polbnda_250k_adm3_mimu.shp"
#tw_geo_MIMU <- st_read(geo_file)


```


```{r PRP}
# Create variables for the geographical data

# create a list of regions and states
rg_list = as.list(rg_geo@data$NAME_1)

# There are 2 townships with the same name in the same Region, so we will use for the Maubin region
# township the name that appears in the VARNAME_3 column: "Danuphyu".
tw_geo@data$NAME_3[tw_geo@data$NAME_2=="Maubin" & tw_geo@data$NAME_3=="Danubyu"] <- "Danuphyu"

# create a list of regions and townships
tw_list = tw_geo@data[,c(4,7,10)]
tw_list <- cbind(id=rownames(tw_list), tw_list)

```


```{r EDA}
# Exploring geographic dataset

# plot maps and coordinates
par(mar = c(0, 0, 0, 0)) # Set the margin on all sides to 0

{plot(st_geo, col = 'lightgrey', border = 'darkgrey')
points(cn_events$longitude, cn_events$latitude, col="red", cex=1)}

# plot nightlights
nl_explore = tw_geo
nl_explore@data$radiance = nl_data[which(nl_data$date=="2012-04-01"), ]$radiance

tm_shape(co_geo) +
    tm_borders(col = "black", lwd = 1) +
tm_shape(nl_explore) + 
  tm_fill(col = "radiance", 
          n = 10,
          palette = "cividis", 
          contrast = c(0,1))+
tm_shape(st_geo) +
    tm_borders(col = "light grey", lwd = 1, lty = "dashed", alpha = 0.6) +
tm_legend(show=FALSE) + 
tm_layout(frame = FALSE)


```


```{r PRP}
# Remove points that lay of the polygons (outsiders) in the conflicts dataset

# create events spatialpolygon with geographical points 
cn_temp <- data.frame(cn_events$longitude,cn_events$latitude)
coordinates(cn_temp) <- ~cn_events.longitude+cn_events.latitude
proj4string(cn_temp) <- proj4string(tw_geo)

# get the numeric index row of outsiders 
cn_events_outsiders = over(cn_temp, tw_geo)
cn_events_outsiders = rownames(cn_events_outsiders[is.na(cn_events_outsiders$GID_0),])
cn_events_outsiders = as.numeric(cn_events_outsiders)

# remove the outsiders from the conflict dataset
cn_events = cn_events %>% 
      filter(!row_number() %in% cn_events_outsiders)

# remove the outsiders from the cn_events dataset (creating it again)
cn_temp <- data.frame(cn_events$longitude,cn_events$latitude)
coordinates(cn_temp) <- ~cn_events.longitude+cn_events.latitude
proj4string(cn_temp) <- proj4string(tw_geo)

# improvement: we may want to include the points that are in the border of the administrative divisions

```


```{r EDA}

# plot the map and coordinates
{plot(st_geo, col = 'lightgrey', border = 'darkgrey')
points(cn_events$longitude, cn_events$latitude, col="red", cex=1)}


```


```{r PRP}
# Attach the administrative divisions names to the events dataframe

cn_temp$NAME_1 = over(cn_temp, tw_geo)$NAME_1
cn_temp$NAME_2 = over(cn_temp, tw_geo)$NAME_2
cn_temp$NAME_3 = over(cn_temp, tw_geo)$NAME_3

# An alternative for the intersection
#gIntersection(cn_temp, tw_geo)

# convert spatialpointsdataframe to dataframe
cn_temp <-  as.data.frame(cn_temp)
names(cn_temp) <- c("region","district","township","longitude","latitude")

# bind the administrative divisions name to the conflicts dataset
region <- with(cn_events, ifelse(cn_events$longitude == cn_temp$longitude & 
                              cn_events$latitude == cn_temp$latitude, 
                                cn_temp$region, ""))

district <- with(cn_events, ifelse(cn_events$longitude == cn_temp$longitude & 
                              cn_events$latitude == cn_temp$latitude, 
                                cn_temp$district, ""))

township <- with(cn_events, ifelse(cn_events$longitude == cn_temp$longitude & 
                              cn_events$latitude == cn_temp$latitude, 
                                cn_temp$township, ""))

cn_events <- cbind(cn_events, region)
cn_events <- cbind(cn_events, district)
cn_events <- cbind(cn_events, township)

# delete variables that we don't need anymore
region <- NULL
district <- NULL
township <- NULL

```


```{r EDA}

# plot those that fall in a specific state
filter <- cn_events[ which(cn_events$region=="Kachin"), ]

{plot(st_geo, col = 'lightgrey', border = 'darkgrey')
points(filter$longitude, filter$latitude, col="red", cex=1)}


```


```{r EDA}

# events by type and state
cn_explore = cn_events[c("year", "type_of_violence", "NAME_1")]
cn_explore = cn_explore %>% count(type_of_violence, NAME_1)

ggplot(cn_explore) +
  geom_point(aes(x=n, y=NAME_1, color=type_of_violence), alpha = 0.4)

ggplot(cn_explore, aes(x=n, fill=type_of_violence, color=type_of_violence)) +
  geom_histogram(position="dodge")


```


```{r PRP}
# Classify events by its severity in deaths

# Severity of event is measured by these 2 variables: number of civilians deaths, and number of total deaths

# Standardize the data to make variables comparable 
# (no need as they are already comparable, i.e., they are both deaths)
cn_events_standarized <- scale(cn_events[c(24,26)])

#set.seed(123)

# Determining the clusters using the Elbow method
#fviz_nbclust(cn_stand, kmeans, method = "wss") +
#   geom_vline(xintercept = 4, linetype = 2) +
#  labs(subtitle = "Elbow method")

# Determining the clusters using the Silhouette method
#fviz_nbclust(cn_stand, kmeans, method = "silhouette")+
#  labs(subtitle = "Silhouette method")

# Determining the clusters using the GAP statistic method
#fviz_nbclust(cn_stand, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
#  labs(subtitle = "Gap statistic method")

# Elbow = 4
# Silhouette = 2,4
# GAP = 1,5
# According to these observations, it's possible to define the number of clusters in 4

```


```{r PRP}
# Classify events by the impacts in deaths from the conflict dataset

# this number is selected based on the previous results
cn_events_clusters = 4

# Calculate and assign the clusters to the cn_events dataset (check the size and centers of kmeans output)
cn_events$severity <- kmeans(cn_events_standarized, cn_events_clusters, nstart=100)$cluster

# Ordered factor, and rename impact levels to a more meaningful ones
cn_events$severity_level = factor(cn_events$severity,
                                  labels = c("Low","Medium","High","Extreme"), 
                                  ordered = TRUE)

```


```{r PRP}
# Create a dataframe with information at conflicts level

# Get unique conflicts by region
cn_conflicts <- unique(cn_events[c("conflict_id", "conflict_name", "region")])
cn_conflicts_list <- unique(cn_events[c("conflict_id", "conflict_name")])

# Calculating the first and last date by conflict_id
for (i in 1:nrow(cn_conflicts_list)) {

  # Select events by conflict id 
  cn_temp = cn_events %>% filter(conflict_id == cn_conflicts_list[i, 1])
  
  # Calculate the length
  parameter_start = min(cn_temp$date_start)
  parameter_end = max(cn_temp$date_start)
  parameter_length = as.numeric(difftime(parameter_end, parameter_start, units="days"))
  
  # assign the start, end and length to each conflict-region row
  for (j in 1:nrow(cn_conflicts)) {

    # assign the data to the conflicts
    if (cn_conflicts[j,1] == cn_conflicts_list[i,1]) {
      cn_conflicts[j,"start"] = parameter_start
      cn_conflicts[j,"end"] = parameter_end
      cn_conflicts[j,"length"] = parameter_length
    }
    
  }

}

```


```{r PRP}
# Add to the events dataframe the length in years of each event

# Initialize column with the length
cn_events$date_length = 0

for (i in 1:nrow(cn_events)) {
  
  parameter_start = as.Date(cn_events[i, 20])
  parameter_end = as.Date(cn_events[i, 21])
  
  cn_events[i, 34] = 
    round(as.numeric(difftime(parameter_end, parameter_start, unit="weeks"))/52.25, digits = 2)

}

```


```{r EDA}
# Visualizing the exploring viz from previous dataframe

parameter_region = "Kachin"
parameter_date = as.Date("2012-04-01")

cn_explore = cn_events_explore[cn_events_explore$NAME_1==parameter_region,]

cn_explore = cn_explore %>%
 filter(date_start >= parameter_date)

# Cleveland Plot
ggplot(cn_explore) +
  geom_segment( aes(x=deaths_total, xend=deaths_total, y=date_start, yend=date_end), color="grey") +
  geom_point( aes(x=deaths_total, y=date_start), color=rgb(0.2,0.7,0.1,0.5), size=1 ) +
  geom_point( aes(x=deaths_total, y=date_end), color=rgb(0.7,0.2,0.1,0.5), size=3) +
  coord_flip()+
  theme(
    legend.position = "none",
    plot.background = element_blank(),
    panel.background = element_rect(fill = "#FFFFFF"),
    panel.border = element_blank(),
    panel.grid = element_line(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_line(size = 0.5, 
                                      linetype = 'dotted',
                                      colour = "black"), 
    panel.grid.major.y = element_line(size = 0.5, 
                                      linetype = 'dotted',
                                      colour = "black"), 
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank()
  ) +
  xlab("") +
  ylab("")


```


```{r PRP}
# Create a dataset with monthly deaths by region from the conflict dataset

# Split the months from the conflicts dataset (in the new columns start_dates and end_dates)
cn_events_monthly <- cn_events %>%
  mutate(test = map2(date_start, date_end, expand_dates)) %>%
  unnest(cols = c(test))

# Add a column with the month
cn_events_monthly$month = month(cn_events_monthly$start_dates)


```


```{r EDA}
# Plotting monthly conflicts by state

parameter_region = "Kachin"

# Select a state
cn_explore = cn_events_monthly[ which(cn_events_monthly$NAME_1==parameter_region),]

# Line graph
ggplot(cn_explore, aes(start_dates, deaths_total)) + geom_line() + scale_x_date(date_labels = "%b-%Y") +
geom_vline(xintercept = as.Date("01-01-2018",  format = "%d-%m-%Y"), linetype = 'dotted', color = 'blue')

# Select the data we need to  draw the map
cn_explore = cn_explore[c("id","longitude","latitude","deaths_total","impact")]
# transform the data to spatial coordinates
coordinates(cn_explore) <- ~longitude+latitude

st_layer = st_geo[st_geo@data$NAME_1==parameter_region,]
tw_layer = tw_geo[tw_geo@data$NAME_1==parameter_region,]

# Map of the selected state with the total_deaths as bubbles
tm_shape(st_layer) +
    tm_borders(col="black", lwd=1) +
tm_shape(tw_layer) +
    tm_borders(col="grey", lwd=1, lty="dashed", alpha=0.6) +
tm_shape(cn_explore) +
    tm_bubbles(size="deaths_total", col="impact") + 
tm_legend(show=TRUE) +
tm_layout(frame=FALSE)


```


```{r EDA}
# Plotting conflicts by impact and region

cn_events_geo = cn_events
coordinates(cn_events_geo) <- ~longitude+latitude


# Select parameters: state and date
parameter_region = "Kachin"

st_layer = st_geo[st_geo@data$NAME_1==parameter_region,]
tw_layer = tw_geo[tw_geo@data$NAME_1==parameter_region,]
cn_layer = cn_events_geo[cn_events_geo@data$region==parameter_region,]

tm_shape(st_layer) +
    tm_borders(col="black", lwd=1) +
tm_shape(tw_layer) +
    tm_borders(col="grey", lwd=1, lty="dashed", alpha=0.6) +
tm_shape(cn_layer) +
  tm_bubbles(col = "impact_level",
          alpha = 0.5,
          #palette = hcl.colors(6, "Tropic"), 
          palette = c("white","pink","red","black"),
          stretch.palette = FALSE,
          size = 0.6)+
tm_legend(show=TRUE) +
tm_layout(frame=FALSE)


```


```{r PRP12}
# Create events, nightlights, and geographical layers

# Select parameters: region and date
parameter_region = "Kachin"
parameter_date = "2018-05-01"

# Select the region and township geographical divisions
rg_layer = rg_geo[rg_geo@data$NAME_1==parameter_region,]
tw_layer = tw_geo[tw_geo@data$NAME_1==parameter_region,]

# Subset the events on the region
ev_filter = cn_events_monthly[which(cn_events_monthly$region==parameter_region), ]
# 282 obs > 96 obs: 1 loc can have more than 1 event as we have spitted them by month
# Subset the events on the date
ev_filter = ev_filter[which(ev_filter$month==month(parameter_date) & ev_filter$year==year(parameter_date)), ]

tw_filter = tw_geo[which(tw_geo@data$NAME_1==parameter_region),]
nl_filter = nl_data[which(nl_data$region==parameter_region),]

# select events information outputs 
ev_layer = ev_filter[c("id", "latitude", "longitude", "deaths_high", "severity")]
# Create a spatial points object
coordinates(ev_layer) <- ~longitude+latitude

# select nightlights period and attach the radiance
nl_layer <- tw_filter
nl_layer@data$radiance = nl_filter[which(nl_filter$date==parameter_date),]$radiance


```


```{r EDA2}
# Plotting monthly conflicts by region

# Map of the selected region with the total_deaths and impact
tm <- tm_shape(nl_layer) + 
  tm_fill(col = "radiance",
          n = 15,
          palette = "cividis",
          contrast = c(0,1)) +

tm_shape(tw_layer) +
    tm_borders(col = "white", 
               lwd = 1, 
               alpha = 0.4) +

tm_shape(ev_layer) +
  tm_bubbles(size="deaths_high", 
             col="impact",
             border.lwd = NA, 
             alpha = 0.9) + 
  
tm_shape(st_layer) +
    tm_borders(col="black", lwd=1) +

tm_legend(show=TRUE) + 
tm_layout("Conflicts Impact",
          legend.title.size = 1,
          legend.text.size = 0.6,
          legend.outside.position = c("left","bottom"),
          legend.bg.color = "white",
          legend.bg.alpha = 1,
          legend.outside = TRUE) +
tm_layout(frame = FALSE)

tm

```


```{r PRP2}
# Create a dataframe with the NL changes by township and region

# initialize dataframe
nl_changes <- data.frame(region=character(),
                         district=character(),
                         township=character(),
                         first=double(),
                         last=double(),
                         stringsAsFactors=FALSE)

# Calculate changes from first NL reading to last NL reading
parameter_start <- as.Date(min(nl_data$date))
parameter_end <- as.Date(max(nl_data$date))

# Changes are normalized by year (like we do with  %  of interest of money):
# the readings change will be divided by the years between the first and last date
parameter_date_years <- as.numeric(difftime(parameter_end, parameter_start, unit="weeks"))/52.25

for (i in 1:length(rg_list)) {
  
  nl_temp = nl_data[which(nl_data$region==rg_list[[i]]), ]
  nl_temp = nl_temp[(nl_temp$date==parameter_start | nl_temp$date==parameter_end),]
  nl_temp = cast(nl_temp, region+district+township~date, mean, value = "radiance")
  names(nl_temp) = c("region", "district", "township", "first", "last")
  nl_temp$change = nl_temp$last/nl_temp$first/parameter_date_years

  # assign levels
  nl_temp = nl_temp %>% 
  mutate(level = case_when(
    change < -0.30 ~ "Strong Decrease",
    change < -0.05 ~ "Decrease",
    change < 0.05 ~ "Similar",
    change < 0.30 ~ "Increase",
    change >= 0.30 ~ "Strong Increase",
  ))
  
  # append the rows to the nl_changes dataframe
  nl_changes = rbind(nl_changes, nl_temp)

}
  
```


```{r EDA2}
# Plotting levels of nightlights change by region

parameter_region = "Shan"

st_layer = st_geo[st_geo@data$NAME_1==parameter_region,]
tw_layer = tw_geo[tw_geo@data$NAME_1==parameter_region,]

nl_layer = tw_geo[which(tw_geo@data$NAME_1==parameter_region),]
nl_layer@data$change = nl_changes[which(nl_changes$region==parameter_region),5]

myBreaks <- c(-1, -0.3, -0.05, 0.05, 0.3, 1)
myLabels <- c("Strong Decrease", "Decrease", "Similar", "Increase", "Strong Increase")
myPalette <- c("#f2f0f7", "#cbc9e2", "#9e9ac8", "#6a51a3", "#6a51a3")

tm_shape(nl_layer) + 
  tm_fill(col = "change",
          #style = "fixed",
          breaks = myBreaks,
          labels = myLabels,
          palette = "RdYlGn",
          contrast = c(0,1)) +

tm_shape(tw_layer) +
    tm_borders(col = "white", 
               lwd = 1, 
               alpha = 0.4) +

tm_shape(st_layer) +
    tm_borders(col="black", lwd=1) +
  
tm_layout(frame = FALSE)


```



```{r LDA}
# Load population data from the census

pp_file <- paste(dir_data,
                 "population/BaselineData_Census_Dataset_SR_District_Township_MIMU_16Jun2016_ENG.xlsx", 
                 sep="", 
                 collapse=NULL)

# Select columns
pp_colTypes <- c("text", # State/Region Pcode
                  "text", # State/Region name
                  "text", # District Pcode
                  "text", # District Name
                  "text", # Township Pcode
                  "text", # Township Name
                  "numeric", # Population total
                  "skip", # Population male
                  "skip", # Population female
                  "skip", # Population sex ratio
                  "skip", # Population total urban
                  "skip", # Population male urban
                  "skip", # Population female urban
                  "skip", # Population sex ratio urban
                  "skip", # Population total rural
                  "skip", # Population male rural
                  "skip", # Population female rural
                  "skip", # Population sex ratio rural
                  "skip") # Urban Population %

pp <- read_xlsx(path=pp_file,
                 sheet = "Table A-3",
                 col_names=TRUE,
                 col_types=pp_colTypes,
                 skip=4)


```


```{r CLN}
# Population dataset cleaning

# change columns names
pp_data = pp %>% select(2,4,6,7)
names(pp_data) = c("region", "district", "township", "population")

# remove NAs (population aggregated at regional level)
pp_data = pp_data[complete.cases(pp_data),]

sum(pp_data$population, na.rm=TRUE)
#50,279,900

```


```{r LDA, eval=FALSE}
# Load the file with the mapping of township names from GADM and from census data

# Select columns
pp_colTypes <- c("numeric", # GADM code
                  "text", # State/Region name
                  "text", # Township Name
                  "numeric", # Census code
                  "text", # State/Region name
                  "text", # township name
                  "text", # Strategy
                  "numeric", # Target
                  "skip") # Notes

pp_file = paste(dir_data,
                "population/2014 Census Administrative Differences.xlsx",
                sep="",
                collapse=NULL)

tw_mapping <- read_xlsx(path=pp_file,
                 sheet = "Mapping",
                 col_names=TRUE,
                 col_types=pp_colTypes,
                 skip=2)

# create a temp tables with the ids to link the population
pp_table = pp_data
pp_table$id = rownames(pp_table)


```



```{r PRP}
# Create a dataframe to store the predictions

# use nl data structure
md_df_pp = nl_data

#attach the area
md_df_pp = merge(x=md_df_pp, 
                 y=nl[,c("division_.yin.","district_.kayaing.","village.township","area_sq_km")],
                 by=c("region","district","township"),
                 by.y=c("division_.yin.","district_.kayaing.","village.township"),
                 all.x=TRUE)
colnames(md_df_pp)[6] <- "area"

#split the date
md_df_pp$month = month(md_df_pp$date)
md_df_pp$year = year(md_df_pp$date)
md_df_pp$date = NULL
#order by date
md_df_pp = md_df_pp[order(md_df_pp$year, md_df_pp$month),]

cn_temp = cn_events
cn_temp$month = month(cn_temp$date_start)
cn_temp = cn_temp[order(cn_temp$year, cn_temp$month),]

# add the new columns
md_df_pp$n_events = 0
md_df_pp$c_deaths = 0
md_df_pp$t_deaths = 0
md_df_pp$population = 0

for (i in 1:nrow(md_df_pp)){
  
  # calculate the NUMBER OF EVENTS by township and date
  # (update with district to catch duplicated townships)
  md_df_pp[i, 8] = cn_temp %>%
    filter(region == md_df_pp[i,1] &
           township == md_df_pp[i,3] &
           month == md_df_pp[i,6] &
           year == md_df_pp[i,7]) %>%
    count()

  # calculate the number of CIVILIAN DEATHS by township and date
  # (update with district to catch duplicated townships)
  md_df_pp[i, 9] = cn_temp %>%
    filter(region == md_df_pp[i,1] &
           township == md_df_pp[i,3] &
           month == md_df_pp[i,6] &
           year == md_df_pp[i,7]) %>%
    summarise(d = sum(deaths_civilians))


  # calculate the number of TOTAL DEATHS by township and date
  # (update with district to catch duplicated townships)
  md_df_pp[i, 10] = cn_temp %>%
    filter(region == md_df_pp[i,1] &
           township == md_df_pp[i,3] &
           month == md_df_pp[i,6] &
           year == md_df_pp[i,7]) %>%
    summarise(d = sum(deaths_total))

}


sum(md_df_pp$n_events, na.rm=TRUE)
#735 (2,757 counting before Apr/2012)

sum(md_df_pp$t_deaths, na.rm=TRUE)
#5,239

# re-organize the columns
col_order <- c("region", "district", "township", "area",
               "month", "year", 
               "n_events", "c_deaths", "t_deaths",
               "radiance", "population")
md_df_pp <- md_df_pp[,col_order]

# backup the data
md_df_pp_backup <- md_df_pp
# restore the data
md_df_pp <- md_df_pp_backup

```


```{r CLN}
# Assign the same names from GADM to the population data

# The census was collected between 30 March and 10 April 2014
parameter_date = as.Date("2014-04-01")

# The census data has been collected using different geographical divisions than the ones in GADM,
# so we need to adjust them to fit census to GADM distribution.
# There will be 4 different strategies to match the data from the census with GADM:

# 1) Direct transfer, when the divisions match in both census and GADM
# 2) Merge with GADM, when one division in the census is completely inside another region of GADM
# 3) Split to GADM, when a division in the census doesn't exist in GADM
# 4) Split from census, when a division in GADM doesn't exist in the census

```


```{r CLN}
# Assign the same names from GADM to the population data
# 1) Direct transfer, when the townships match in both census and GADM

# Select the townships we are going to transfer
tw_mapping_selected = tw_mapping[tw_mapping$Strategy == "Direct Transfer",]

# add population to mapping from the pop_table
tw_mapping_selected = merge(tw_mapping_selected, pp_table, by.x="census", by.y="id")

for (i in 1:nrow(md_df_pp)){

    # control that is the period from the census
    if ((as.numeric(md_df_pp[i,5]) == as.numeric(month(parameter_date))) &&
        (as.numeric(md_df_pp[i,6]) == as.numeric(year(parameter_date)))) {
      
        md_df_pp[i,11] = 
            tw_mapping_selected %>%
            filter(
              NAME_1 == md_df_pp[i,1] &
              NAME_3 == md_df_pp[i,3]) %>%
            summarise(p = sum(population))
    } 
}

sum(md_df_pp$population, na.rm=TRUE)
# 41,592,810

```


```{r CLN}
# Assign the same names from GADM to the population data

# 2) Merge with GADM, when one division in the census is completely inside another region of GADM

# Select the townships we are going to transfer, those that start with "merge with"
tw_mapping_selected = subset(tw_mapping, grepl("Merge with", Strategy))

# add region and township to mapping from the tw_list
tw_mapping_selected = merge(tw_mapping_selected, tw_list, by.x="Target", by.y="id")

# add population to mapping from the pp_table
tw_mapping_selected = merge(tw_mapping_selected, pp_table, by.x="census", by.y="id")

# Top up the population
for (i in 1:nrow(tw_mapping_selected)){
    
    # find the record in the md_df_pp
    for (j in 1:nrow(md_df_pp)){
      
      if (
          (as.numeric(md_df_pp[j,5]) == as.numeric(month(parameter_date))) &&
          (as.numeric(md_df_pp[j,6]) == as.numeric(year(parameter_date))) &&
          (md_df_pp[j,1] == tw_mapping_selected[i,9]) &&
          (md_df_pp[j,3] == tw_mapping_selected[i,11])){
  
            md_df_pp[j,11] = md_df_pp[j,11] + tw_mapping_selected[i,15]
            break
      }
    }
}

sum(md_df_pp$population, na.rm=TRUE)
#49,145,022

```


```{r CLN}
# Assign the same names from GADM to the population data

# 3) Split to GADM, when a division in the census doesn't exist in GADM
# 4) Split from census, when a division in GADM doesn't exist in the census

# There are only 5 cases here, so we do it manually
tw_mapping_selected <- subset(tw_mapping, grepl("Split to", Strategy))

# add population to mapping from the pop_table
tw_mapping_selected = merge(tw_mapping_selected, pp_table, by.x="census", by.y="id")

# case 1: Myinmu to ADD Myinmu (50%) and ADD to Ngazun (50%)
md_df_pp[which(md_df_pp$region=="Sagaing" &
                          md_df_pp$township == "Myinmu" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[1,12]*0.5)

md_df_pp[which(md_df_pp$region=="Sagaing" &
                          md_df_pp$township == "Ngazun" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[1,12]*0.5)

# case 2: Kanbalu ADD to Kanbalu (80%) and ADD to Tantabin (20%)
md_df_pp[which(md_df_pp$region=="Sagaing" &
                          md_df_pp$township == "Kanbalu" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[2,12]*0.8)

md_df_pp[which(md_df_pp$region=="Sagaing" &
                          md_df_pp$township == "Tantabin" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[2,12]*0.2)

# case 3: Kangyidaunt TOP UP to Bassein West (40%) and TOP UP to Ngaputaw (60%)
# store the current population for Bassein West
pp_base <- md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Bassein West" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11]

md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Bassein West" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- pp_base + round(tw_mapping_selected[3,12]*0.4)

# store the current population for Ngaputaw
pp_base <- md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Ngaputaw" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11]

md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Ngaputaw" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- pp_base + round(tw_mapping_selected[3,12]*0.6)

# case 4: Nyaungdon ADD to Yandoon (60%) and ADD to Irrawaddy (40%)
md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Yandoon" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[4,12]*0.6)

md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Irrawaddy" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[4,12]*0.4)

# case 5: Hinthada ADD to Henzada (50%) and to Danubyu (50%)
md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Henzada" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[5,12]*0.5)

md_df_pp[which(md_df_pp$region=="Ayeyarwady" &
                          md_df_pp$township == "Danubyu" &
                          md_df_pp$month == 4 &
                          md_df_pp$year == 2014), 11] <- round(tw_mapping_selected[5,12]*0.5)

sum(md_df_pp$population, na.rm=TRUE)
#50,279,900

```


```{r MOD}
# Create a model that predicts people movs from radiance and conflict data

# Cannot predict future movements of people as we dont have the deaths neither rads preds,
# so what we can do is predict past human movements, beinG population the variable to predict,
# not radiance as we thought, at least by now....

# we can estimate the correlation between radiance and population

# https://srnghn.medium.com/machine-learning-trying-to-predict-a-numerical-value-8aafb9ad4d36


# backup the df
md_df_pp_backup <- md_df_pp 

```


```{r MOD}
# Linear Regression

#http://r-statistics.co/Linear-Regression.html
#http://r-statistics.co/adv-regression-models.html

set.seed(100)

# Select observations where we have population to train the model
md_df <- md_df_pp[md_df_pp$population>0,]

# Create training and test data
md_rowIndex <- sample(1:nrow(md_df), 0.8*nrow(md_df)) # row indices for training data
md_df_training <- md_df[md_rowIndex, ] # model training data
md_df_testing  <- md_df[-md_rowIndex, ] # test data

# Build the model on training dataset
md_lm <- lm(population ~ radiance+area, data=md_df_training)

# Evaluate the model
summary(md_lm)
AIC(md_lm)

# Generate the predictions of population on test dataset
predictions <- predict(md_lm, md_df_testing)

# Attach previous predictions to the test dataset
md_df_preds <- data.frame(cbind(actual=md_df_testing$population, predicted=predictions))

# Evaluate the predictions
md_lm_corrAccuracy <- cor(md_df_preds)
md_min_max_accuracy <- mean(apply(md_df_preds, 1, min) / apply(md_df_preds, 1, max))  
md_mape <- mean(abs((md_df_preds$predicted - md_df_preds$actual))/md_df_preds$actual)  

# k-Fold cross validation
library(DAAG)
cvResults <- suppressWarnings(CVlm(md_df, 
                                   form.lm=population ~ n_events+c_deaths+t_deaths+radiance, 
                                   m=5, 
                                   dots=FALSE, 
                                   seed=29, 
                                   legend.pos="topleft",  
                                   printit=FALSE, 
                                   main="Small symbols are predicted values while bigger ones are actuals")); 

# performs the CV
attr(cvResults, 'ms')  # => 251.2783 mean squared error

```


```{r MOD}

# K-Nearest Neigbours




```



```{r MOD}

# Use model to predict data that we donÂ´t know

md_temp <- md_df_pp[md_df_pp$population==0,]
predictions <- predict(md_lm, md_temp) # predict population

md_df_preds <- data.frame(cbind(md_final, predictions))
md_df_preds$population = NULL
colnames(md_df_preds)[11] <- "population"
md_final <- data.frame(rbind(md_df,md_df_preds))

```


```{r EDA23}
# Ploting the prediction

# https://www.r-graph-gallery.com/283-the-hourly-heatmap.html


data <- data(Trentino_hourly_T,package = "Interpol.T")
 
names(h_d_t)[1:5]<- c("stationid","date","hour","temp","flag")
df <- tbl_df(h_d_t) %>%
  filter(stationid =="T0001")
 
df <- df %>% mutate(year = year(date),
                  month = month(date),
                  day = day(date))
  
df$date<-ymd(df$date) # not necessary for plot but 
#useful if you want to do further work with the data
 
#cleanup
rm(list=c("h_d_t","mo_bias","Tn","Tx",
          "Th_int_list","calibration_l",
          "calibration_shape","Tm_list"))
 
 
#create plotting df
df <-df %>% select(stationid,day,hour,month,year,temp)%>%
        fill(temp) #optional - see note below


md_temp = md_final[md_final$region == parameter_region,]
 
    p <- ggplot(md_temp, aes(month, township, fill=population)) +
          geom_tile(color="white", size=0.5) + 
          scale_fill_viridis(name="Population", option="E") +
          facet_grid(.~year)
    
    p <- p + theme(
      panel.spacing.x=unit(0.05, "lines"), 
      panel.spacing.y=unit(0.01, "npc"),
      panel.background = element_rect(fill = "#F5F5F5", color = "#F5F5F5"),
      plot.background = element_rect(fill = "#F5F5F5", color = "#F5F5F5"),
      plot.title=element_blank(),
      legend.position = "none",
      axis.title.y=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank(),
      axis.title.x=element_blank(),
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      strip.background = element_blank()
      ) +
        xlab("") + 
        ylab("") +
        removeGrid()

    ggplotly(p)
    
```



```{r PRP}
# Assign the same names from GADM to the population data

# Export files for the web app

# Save dataframes
cn_file = "E:/Data Lights/Shiny/cn_events.rda"
save(cn_events, file=cn_file)

cn_file = "E:/Data Lights/Shiny/cn_events_geo.rda"
save(cn_events_geo, file=cn_file)

cn_file = "E:/Data Lights/Shiny/cn_conflicts_list.rda"
save(cn_conflicts_list, file=cn_file)

cn_file = "E:/Data Lights/Shiny/cn_events_explore.rda"
save(cn_events_explore, file=cn_file)

nl_file = "E:/Data Lights/Shiny/nl_data.rda"
save(nl_data, file=nl_file)

nl_file = "E:/Data Lights/Shiny/nl_changes.rda"
save(nl_changes, file=nl_file)

md_file = "E:/Data Lights/Shiny/md_final.rda"
save(md_final, file=md_file)

```

